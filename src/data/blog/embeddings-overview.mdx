---
pubDatetime: 2025-06-10
category: AI
series: embeddings
title: What Are Embeddings?
draft: false
image: /og-images/articles/embeddings/proc.webp
tags:
  - AI
  - Embeddings
description: Transform complex information into a form that is understandable for machine learning algorithms.
---

![Cover Image](/og-images/articles/embeddings/proc.webp)

# ğŸ§  Embeddings Made Simple

## ğŸ“˜ What Are Embeddings?

Embeddings are a way to convert complex data (like words, images, or graphs) into number-based formats (vectors) that machines can understand.  
They help models recognize **patterns**, **relationships**, and **similarities** between things.

![Image Classification](/og-images/articles/embeddings/king-qween-clasiffication.webp)

---

## ğŸ’¡ Simple Example

Words like: `king`, `queen`, `prince`, `princess`

### ğŸ§¾ One-hot Encoding (Old Style)
| Word     | One-hot Vector |
| -------- | -------------- |
| queen    | [1, 0, 0, 0]   |
| king     | [0, 1, 0, 0]   |
| princess | [0, 0, 1, 0]   |
| prince   | [0, 0, 0, 1]   |

ğŸš« Doesn't show how words are related.

### ğŸ”— Embeddings (Better)
| Word     | [Gender, Age] |
| -------- | ------------- |
| queen    | [1, 0]        |
| king     | [0, 0]        |
| princess | [1, 1]        |
| prince   | [0, 1]        |

âœ… Shows gender and age â€” useful relationships!

---

## ğŸš€ Where Are Embeddings Used?

- ğŸ¬ **Recommendation Systems** â€“ Suggest movies, products, etc.
- ğŸ—£ï¸ **Natural Language Processing (NLP)** â€“ Search, chatbots, summarizers.
- ğŸ–¼ï¸ **Image & Audio Analysis** â€“ Facial recognition, voice ID.

---

## ğŸ”¢ Types of Embeddings

### ğŸ§© Word Embeddings
- Represent individual words as vectors.
- Examples: `Word2Vec`, `GloVe`, `FastText`.

### ğŸ§¾ Sentence Embeddings
- Represent full sentences or paragraphs.
- Examples: `SBERT`, `Universal Sentence Encoder`.

### ğŸ–¼ï¸ Image Embeddings
- Convert images into vectors.
- Help models find and classify images.

### ğŸ•¸ï¸ Graph Embeddings
- Represent nodes in a network (like users in social media).
- Useful for detecting relationships and communities.

![Types](/og-images/articles/embeddings/type_of_embedding.webp)

---

## ğŸ§° Key Embedding Models

### âš™ï¸ Word2Vec (by Google)
- **CBOW**: Predicts a word from its neighbors.
- **Skip-Gram**: Predicts neighbors from a word.
- Captures relationships like: `"king" - "man" + "woman" â‰ˆ "queen"`

### ğŸ§® GloVe (by Stanford)
- Counts word co-occurrences.
- Vectors show how often words appear together.
- E.g., `"ice"` and `"snow"` are close.

### ğŸ§  BERT (by Google)
- Context-aware: understands `"bank"` can mean river or money.
- **Bidirectional**: Looks at words before and after.
- Used for QA, classification, and more.

### ğŸ§¾ GPT (by OpenAI)
- Great at generating text: stories, articles, code.
- **Unidirectional**: Looks only at past words.
- Example: Given `"Once upon a time,"` it writes a whole story.

---

ğŸ“ In short: Embeddings are how machines make sense of complex stuff like text, images, or relationships â€” turning them into numbers that carry meaning.
